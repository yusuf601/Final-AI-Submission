{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23018624-89cb-4e6a-8c82-54d7515143f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba1378db-088f-4d69-b884-5656799ca3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOADING RAW FEATURES\n",
      "================================================================================\n",
      "✓ Loaded: /home/kali/AI/fcm_features_raw.csv\n",
      "  Shape: (34, 50)\n",
      "  Provinces: 34\n",
      "  Features: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING RAW FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "input_file = '/home/kali/AI/fcm_features_raw.csv'\n",
    "output_file = '/home/kali/AI/fcm_features_standardized.csv'\n",
    "\n",
    "df_raw = pd.read_csv(input_file, index_col=0)  # index_col=0 → Province as index\n",
    "\n",
    "print(f\"✓ Loaded: {input_file}\")\n",
    "print(f\"  Shape: {df_raw.shape}\")\n",
    "print(f\"  Provinces: {len(df_raw)}\")\n",
    "print(f\"  Features: {len(df_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bc367a-8dc3-4b61-8c12-c6da2d34d110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA VALIDATION\n",
      "================================================================================\n",
      "✓ No missing values\n",
      "✓ No infinite values\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "missing_count = df_raw.isnull().sum().sum()\n",
    "if missing_count > 0:\n",
    "    print(f\"⚠️ WARNING: {missing_count} missing values found!\")\n",
    "    print(\"\\nProvinces with missing:\")\n",
    "    print(df_raw.isnull().sum(axis=1)[df_raw.isnull().sum(axis=1) > 0])\n",
    "    \n",
    "    print(\"\\nFeatures with missing:\")\n",
    "    missing_features = df_raw.isnull().sum()\n",
    "    print(missing_features[missing_features > 0])\n",
    "    \n",
    "    # Handle missing (impute with column mean)\n",
    "    print(\"\\n⚠️ Filling missing values with column mean...\")\n",
    "    df_raw = df_raw.fillna(df_raw.mean())\n",
    "    print(\"✓ Missing values filled\")\n",
    "else:\n",
    "    print(\"✓ No missing values\")\n",
    "\n",
    "# Check for infinite values\n",
    "inf_count = np.isinf(df_raw.values).sum()\n",
    "if inf_count > 0:\n",
    "    print(f\"⚠️ WARNING: {inf_count} infinite values found!\")\n",
    "    df_raw = df_raw.replace([np.inf, -np.inf], np.nan).fillna(df_raw.mean())\n",
    "    print(\"✓ Infinite values replaced with column mean\")\n",
    "else:\n",
    "    print(\"✓ No infinite values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c8aa410-13b8-43d0-8461-ac06cc2a7c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STATISTICS BEFORE STANDARDIZATION\n",
      "================================================================================\n",
      "\n",
      "Feature ranges (sample - showing different commodity types):\n",
      "--------------------------------------------------------------------------------\n",
      "Mean_Bawang_Putih_Bonggol           | Mean:  34,946.02 | Std:   5,190.07 | Range:  19,869.63\n",
      "Mean_Cabai_Merah_Keriting           | Mean:  49,416.78 | Std:   9,485.71 | Range:  35,025.80\n",
      "Mean_Daging_Ayam_Ras                | Mean:  37,274.56 | Std:   5,505.40 | Range:  20,590.64\n",
      "Mean_Daging_Sapi_Murni              | Mean: 136,550.49 | Std:  12,100.57 | Range:  45,556.46\n",
      "Mean_Tepung_Terigu_Curah            | Mean:  10,745.95 | Std:     864.99 | Range:   3,411.39\n",
      "Mean_bawang_merah                   | Mean:  37,154.89 | Std:   6,854.18 | Range:  28,178.75\n",
      "Mean_beras_medium                   | Mean:  12,351.29 | Std:     937.75 | Range:   2,979.09\n",
      "Mean_beras_premium                  | Mean:  14,126.90 | Std:   1,238.50 | Range:   3,744.72\n",
      "\n",
      "Overall statistics:\n",
      "  Mean of all features: 7,552.84\n",
      "  Std of all features:  924.14\n",
      "  Min value overall:    -1.70\n",
      "  Max value overall:    159,027.41\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICS BEFORE STANDARDIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nFeature ranges (sample - showing different commodity types):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Sample features from different types\n",
    "sample_features = [\n",
    "    'Mean_bawang_merah',      # High volatility vegetable\n",
    "    'Mean_cabai_merah',       # Very high volatility\n",
    "    'Mean_daging_sapi',       # Low volatility, high price\n",
    "    'Mean_tepung_terigu',     # Low volatility, low price\n",
    "    'CV_bawang_merah',        # Volatility metric\n",
    "    'CV_daging_sapi',         # Volatility metric\n",
    "    'Std_bawang_merah',       # Absolute volatility\n",
    "    'Std_daging_sapi'         # Absolute volatility\n",
    "]\n",
    "\n",
    "# Adjust feature names based on actual columns\n",
    "sample_features = [f for f in sample_features if f in df_raw.columns]\n",
    "\n",
    "# Add any actual column if sample not found\n",
    "if len(sample_features) < 6:\n",
    "    sample_features = df_raw.columns[:8].tolist()\n",
    "\n",
    "for feature in sample_features:\n",
    "    min_val = df_raw[feature].min()\n",
    "    max_val = df_raw[feature].max()\n",
    "    mean_val = df_raw[feature].mean()\n",
    "    std_val = df_raw[feature].std()\n",
    "    range_val = max_val - min_val\n",
    "    \n",
    "    print(f\"{feature[:35]:35s} | Mean: {mean_val:10,.2f} | Std: {std_val:10,.2f} | Range: {range_val:10,.2f}\")\n",
    "\n",
    "print(\"\\nOverall statistics:\")\n",
    "print(f\"  Mean of all features: {df_raw.mean().mean():,.2f}\")\n",
    "print(f\"  Std of all features:  {df_raw.std().mean():,.2f}\")\n",
    "print(f\"  Min value overall:    {df_raw.min().min():,.2f}\")\n",
    "print(f\"  Max value overall:    {df_raw.max().max():,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f7af2af-1043-45ba-8fe5-4641b416f30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "APPLYING Z-SCORE STANDARDIZATION\n",
      "================================================================================\n",
      "✓ Standardization complete\n",
      "  All features transformed to Z-scores (mean=0, std=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APPLYING Z-SCORE STANDARDIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform\n",
    "features_standardized = scaler.fit_transform(df_raw)\n",
    "\n",
    "# Convert back to DataFrame (preserve index and columns)\n",
    "df_standardized = pd.DataFrame(\n",
    "    features_standardized,\n",
    "    index=df_raw.index,\n",
    "    columns=df_raw.columns\n",
    ")\n",
    "\n",
    "print(\"✓ Standardization complete\")\n",
    "print(f\"  All features transformed to Z-scores (mean=0, std=1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab83962-646d-4995-a655-fbc38ec6f827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STATISTICS AFTER STANDARDIZATION\n",
      "================================================================================\n",
      "\n",
      "Feature Z-score ranges (sample):\n",
      "--------------------------------------------------------------------------------\n",
      "Mean_Bawang_Putih_Bonggol           | Mean: -0.0000 | Std: 1.0150 | Range: [ -1.23,   2.66]\n",
      "Mean_Cabai_Merah_Keriting           | Mean: -0.0000 | Std: 1.0150 | Range: [ -1.64,   2.11]\n",
      "Mean_Daging_Ayam_Ras                | Mean: -0.0000 | Std: 1.0150 | Range: [ -1.77,   2.03]\n",
      "Mean_Daging_Sapi_Murni              | Mean:  0.0000 | Std: 1.0150 | Range: [ -1.94,   1.89]\n",
      "Mean_Tepung_Terigu_Curah            | Mean: -0.0000 | Std: 1.0150 | Range: [ -1.46,   2.54]\n",
      "Mean_bawang_merah                   | Mean:  0.0000 | Std: 1.0150 | Range: [ -1.25,   2.92]\n",
      "Mean_beras_medium                   | Mean: -0.0000 | Std: 1.0150 | Range: [ -1.27,   1.95]\n",
      "Mean_beras_premium                  | Mean: -0.0000 | Std: 1.0150 | Range: [ -1.19,   1.88]\n",
      "\n",
      "Overall statistics:\n",
      "  Mean of all features:  0.000000  (should be ~0)\n",
      "  Std of all features:   1.015038  (should be ~1)\n",
      "  Min Z-score overall:     -4.992\n",
      "  Max Z-score overall:      3.467\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICS AFTER STANDARDIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nFeature Z-score ranges (sample):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for feature in sample_features:\n",
    "    min_val = df_standardized[feature].min()\n",
    "    max_val = df_standardized[feature].max()\n",
    "    mean_val = df_standardized[feature].mean()\n",
    "    std_val = df_standardized[feature].std()\n",
    "    range_val = max_val - min_val\n",
    "    \n",
    "    print(f\"{feature[:35]:35s} | Mean: {mean_val:7.4f} | Std: {std_val:6.4f} | Range: [{min_val:6.2f}, {max_val:6.2f}]\")\n",
    "\n",
    "print(\"\\nOverall statistics:\")\n",
    "print(f\"  Mean of all features:  {df_standardized.mean().mean():8.6f}  (should be ~0)\")\n",
    "print(f\"  Std of all features:   {df_standardized.std().mean():8.6f}  (should be ~1)\")\n",
    "print(f\"  Min Z-score overall:   {df_standardized.min().min():8.3f}\")\n",
    "print(f\"  Max Z-score overall:   {df_standardized.max().max():8.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0411452f-c254-424a-a0d3-197989a524e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VALIDATION\n",
      "================================================================================\n",
      "✓ Mean check PASSED: 1.03e-15 ≈ 0\n",
      "⚠️ Std check WARNING: 1.015038 (expected ~1)\n",
      "✓ No missing values introduced\n",
      "✓ No infinite values introduced\n",
      "✓ Shape preserved: (34, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check 1: Mean should be ~0\n",
    "mean_check = abs(df_standardized.mean().mean())\n",
    "if mean_check < 1e-10:\n",
    "    print(f\"✓ Mean check PASSED: {mean_check:.2e} ≈ 0\")\n",
    "else:\n",
    "    print(f\"⚠️ Mean check WARNING: {mean_check:.2e} (expected ~0)\")\n",
    "\n",
    "# Check 2: Std should be ~1\n",
    "std_check = df_standardized.std().mean()\n",
    "if 0.99 < std_check < 1.01:\n",
    "    print(f\"✓ Std check PASSED: {std_check:.6f} ≈ 1\")\n",
    "else:\n",
    "    print(f\"⚠️ Std check WARNING: {std_check:.6f} (expected ~1)\")\n",
    "\n",
    "# Check 3: No missing values introduced\n",
    "if df_standardized.isnull().sum().sum() == 0:\n",
    "    print(\"✓ No missing values introduced\")\n",
    "else:\n",
    "    print(f\"⚠️ WARNING: {df_standardized.isnull().sum().sum()} missing values introduced!\")\n",
    "\n",
    "# Check 4: No infinite values introduced\n",
    "if not np.isinf(df_standardized.values).any():\n",
    "    print(\"✓ No infinite values introduced\")\n",
    "else:\n",
    "    print(f\"⚠️ WARNING: Infinite values introduced!\")\n",
    "\n",
    "# Check 5: Shape preserved\n",
    "if df_standardized.shape == df_raw.shape:\n",
    "    print(f\"✓ Shape preserved: {df_standardized.shape}\")\n",
    "else:\n",
    "    print(f\"⚠️ WARNING: Shape changed from {df_raw.shape} to {df_standardized.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa2c150-c19b-4a65-9af7-6963488b9621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DETAILED STD VALIDATION (Per Feature)\n",
      "================================================================================\n",
      "\n",
      "Std statistics across 50 features:\n",
      "  Min:    1.0150384378\n",
      "  Max:    1.0150384378\n",
      "  Mean:   1.0150384378\n",
      "  Median: 1.0150384378\n",
      "\n",
      "✓ Features with std within ±0.001 of 1.0: 0/50\n",
      "⚠️ 50 features outside tolerance\n",
      "Problematic features:\n",
      "  Mean_Bawang_Putih_Bonggol: 1.015038\n",
      "  Mean_Cabai_Merah_Keriting: 1.015038\n",
      "  Mean_Daging_Ayam_Ras: 1.015038\n",
      "  Mean_Daging_Sapi_Murni: 1.015038\n",
      "  Mean_Tepung_Terigu_Curah: 1.015038\n",
      "  Mean_bawang_merah: 1.015038\n",
      "  Mean_beras_medium: 1.015038\n",
      "  Mean_beras_premium: 1.015038\n",
      "  Mean_gula: 1.015038\n",
      "  Mean_telur_ayam: 1.015038\n",
      "  CV_Bawang_Putih_Bonggol: 1.015038\n",
      "  CV_Cabai_Merah_Keriting: 1.015038\n",
      "  CV_Daging_Ayam_Ras: 1.015038\n",
      "  CV_Daging_Sapi_Murni: 1.015038\n",
      "  CV_Tepung_Terigu_Curah: 1.015038\n",
      "  CV_bawang_merah: 1.015038\n",
      "  CV_beras_medium: 1.015038\n",
      "  CV_beras_premium: 1.015038\n",
      "  CV_gula: 1.015038\n",
      "  CV_telur_ayam: 1.015038\n",
      "  Trend_Bawang_Putih_Bonggol: 1.015038\n",
      "  Trend_Cabai_Merah_Keriting: 1.015038\n",
      "  Trend_Daging_Ayam_Ras: 1.015038\n",
      "  Trend_Daging_Sapi_Murni: 1.015038\n",
      "  Trend_Tepung_Terigu_Curah: 1.015038\n",
      "  Trend_bawang_merah: 1.015038\n",
      "  Trend_beras_medium: 1.015038\n",
      "  Trend_beras_premium: 1.015038\n",
      "  Trend_gula: 1.015038\n",
      "  Trend_telur_ayam: 1.015038\n",
      "  Autocorr_Bawang_Putih_Bonggol: 1.015038\n",
      "  Autocorr_Cabai_Merah_Keriting: 1.015038\n",
      "  Autocorr_Daging_Ayam_Ras: 1.015038\n",
      "  Autocorr_Daging_Sapi_Murni: 1.015038\n",
      "  Autocorr_Tepung_Terigu_Curah: 1.015038\n",
      "  Autocorr_bawang_merah: 1.015038\n",
      "  Autocorr_beras_medium: 1.015038\n",
      "  Autocorr_beras_premium: 1.015038\n",
      "  Autocorr_gula: 1.015038\n",
      "  Autocorr_telur_ayam: 1.015038\n",
      "  Skewness_Bawang_Putih_Bonggol: 1.015038\n",
      "  Skewness_Cabai_Merah_Keriting: 1.015038\n",
      "  Skewness_Daging_Ayam_Ras: 1.015038\n",
      "  Skewness_Daging_Sapi_Murni: 1.015038\n",
      "  Skewness_Tepung_Terigu_Curah: 1.015038\n",
      "  Skewness_bawang_merah: 1.015038\n",
      "  Skewness_beras_medium: 1.015038\n",
      "  Skewness_beras_premium: 1.015038\n",
      "  Skewness_gula: 1.015038\n",
      "  Skewness_telur_ayam: 1.015038\n"
     ]
    }
   ],
   "source": [
    "# Tambahkan validation ini:\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED STD VALIDATION (Per Feature)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "per_feature_std = df_standardized.std()\n",
    "print(f\"\\nStd statistics across 50 features:\")\n",
    "print(f\"  Min:    {per_feature_std.min():.10f}\")\n",
    "print(f\"  Max:    {per_feature_std.max():.10f}\")\n",
    "print(f\"  Mean:   {per_feature_std.mean():.10f}\")\n",
    "print(f\"  Median: {per_feature_std.median():.10f}\")\n",
    "\n",
    "# Check how many features have std ≈ 1.0\n",
    "tolerance = 0.001\n",
    "within_tolerance = ((per_feature_std - 1.0).abs() < tolerance).sum()\n",
    "print(f\"\\n✓ Features with std within ±{tolerance} of 1.0: {within_tolerance}/{len(per_feature_std)}\")\n",
    "\n",
    "if within_tolerance == len(per_feature_std):\n",
    "    print(\"✓ ALL FEATURES PASSED: std ≈ 1.0 for each feature\")\n",
    "else:\n",
    "    print(f\"⚠️ {len(per_feature_std) - within_tolerance} features outside tolerance\")\n",
    "    print(\"Problematic features:\")\n",
    "    outlier_features = per_feature_std[(per_feature_std - 1.0).abs() >= tolerance]\n",
    "    for feat, std_val in outlier_features.items():\n",
    "        print(f\"  {feat}: {std_val:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53d24640-dc01-475f-8168-46a5d26359e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VARIANCE PRESERVATION CHECK\n",
      "================================================================================\n",
      "\n",
      "Comparing feature variances (std) before and after:\n",
      "--------------------------------------------------------------------------------\n",
      "Feature                             |    Std (Raw) |  Std (Z-score) |    Ratio\n",
      "--------------------------------------------------------------------------------\n",
      "Mean_Bawang_Putih_Bonggol           |     5,190.07 |         1.0150 |   1.0150\n",
      "Mean_Cabai_Merah_Keriting           |     9,485.71 |         1.0150 |   1.0150\n",
      "Mean_Daging_Ayam_Ras                |     5,505.40 |         1.0150 |   1.0150\n",
      "Mean_Daging_Sapi_Murni              |    12,100.57 |         1.0150 |   1.0150\n",
      "Mean_Tepung_Terigu_Curah            |       864.99 |         1.0150 |   1.0150\n",
      "\n",
      "✓ All features now have std ≈ 1.0\n",
      "✓ RELATIVE variances preserved (high-variance features still identifiable)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VARIANCE PRESERVATION CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nComparing feature variances (std) before and after:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Feature':35s} | {'Std (Raw)':>12s} | {'Std (Z-score)':>14s} | {'Ratio':>8s}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for feature in sample_features[:5]:  # Show first 5 for brevity\n",
    "    std_raw = df_raw[feature].std()\n",
    "    std_z = df_standardized[feature].std()\n",
    "    ratio = std_z  # Should be 1.0 after standardization\n",
    "    \n",
    "    print(f\"{feature[:35]:35s} | {std_raw:12,.2f} | {std_z:14.4f} | {ratio:8.4f}\")\n",
    "\n",
    "print(\"\\n✓ All features now have std ≈ 1.0\")\n",
    "print(\"✓ RELATIVE variances preserved (high-variance features still identifiable)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676727eb-8aec-4bd4-9a4c-39cd57299bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VARIANCE DISCREPANCY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Number of observations (N): 34\n",
      "Expected ratio [sqrt(N/(N-1))]: 1.015038\n",
      "\n",
      "Actual std ratios (sample):\n",
      "  Mean of all stds: 1.015038\n",
      "  Min std:          1.015038\n",
      "  Max std:          1.015038\n",
      "\n",
      "✅ DIAGNOSIS: Sample vs Population std issue\n",
      "   This is NORMAL and SAFE!\n",
      "   Standardization is working correctly.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "OPTIONAL FIX: Use ddof=0 for validation\n",
      "--------------------------------------------------------------------------------\n",
      "Std with ddof=0 (population): 1.000000\n",
      "Expected: 1.000000\n",
      "✅ CONFIRMED: Standardization is CORRECT!\n",
      "   The 1.015 value is due to pandas ddof=1 default\n"
     ]
    }
   ],
   "source": [
    "# Check if the discrepancy is consistent (1.015×)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VARIANCE DISCREPANCY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Theory: sample_std = population_std × sqrt(N/(N-1))\n",
    "N = len(df_standardized)\n",
    "expected_ratio = np.sqrt(N / (N - 1))\n",
    "\n",
    "print(f\"\\nNumber of observations (N): {N}\")\n",
    "print(f\"Expected ratio [sqrt(N/(N-1))]: {expected_ratio:.6f}\")\n",
    "\n",
    "# Check actual ratios\n",
    "actual_ratios = df_standardized.std()\n",
    "print(f\"\\nActual std ratios (sample):\")\n",
    "print(f\"  Mean of all stds: {actual_ratios.mean():.6f}\")\n",
    "print(f\"  Min std:          {actual_ratios.min():.6f}\")\n",
    "print(f\"  Max std:          {actual_ratios.max():.6f}\")\n",
    "\n",
    "# Verify consistency\n",
    "if abs(actual_ratios.mean() - expected_ratio) < 0.001:\n",
    "    print(\"\\n✅ DIAGNOSIS: Sample vs Population std issue\")\n",
    "    print(\"   This is NORMAL and SAFE!\")\n",
    "    print(\"   Standardization is working correctly.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ WARNING: Unexpected std pattern!\")\n",
    "    print(\"   Investigate further.\")\n",
    "\n",
    "# Alternative: Force std=1.0000 by using population std\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"OPTIONAL FIX: Use ddof=0 for validation\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Recalculate with ddof=0 (population std)\n",
    "std_pop = df_standardized.std(ddof=0)\n",
    "print(f\"Std with ddof=0 (population): {std_pop.mean():.6f}\")\n",
    "print(\"Expected: 1.000000\")\n",
    "\n",
    "if abs(std_pop.mean() - 1.0) < 1e-6:\n",
    "    print(\"✅ CONFIRMED: Standardization is CORRECT!\")\n",
    "    print(\"   The 1.015 value is due to pandas ddof=1 default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f7a17ad-84c6-416a-92c7-722fc5827a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAVING STANDARDIZED FEATURES\n",
      "================================================================================\n",
      "✓ Saved: /home/kali/AI/fcm_features_standardized.csv\n",
      "  Shape: (34, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING STANDARDIZED FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_standardized.to_csv(output_file)\n",
    "print(f\"✓ Saved: {output_file}\")\n",
    "print(f\"  Shape: {df_standardized.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeede54-6738-447d-bd21-a572542cbfaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
