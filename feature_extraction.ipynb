{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdfd7d4e-b64d-45ed-b91b-e1ed4c3378a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import cluster\n",
    "from pathlib import Path\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bebeb9b9-0eb0-4a62-abd8-ea64848362af",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CLEANED_PATH = 'path/to/output/cleaned/'  # ← UPDATE THIS PATH!\n",
    "\n",
    "# Expected commodities (10 after dropping Minyak Goreng)\n",
    "EXPECTED_COMMODITIES = [\n",
    "    'bawang_merah',\n",
    "    'beras_medium',\n",
    "    'beras_premium',\n",
    "    'telur_ayam',\n",
    "    'gula',\n",
    "    'Bawang_Putih_Bonggol',\n",
    "    'Cabai_Merah_Keriting',\n",
    "    'Daging_Ayam_Ras',\n",
    "    'Daging_Sapi_Murni',\n",
    "    'Tepung_Terigu_Curah'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5137fa-c071-4cae-b334-ca8298468b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration:\n",
      "  Data path: path/to/output/cleaned/\n",
      "  Expected commodities: 10\n",
      "  Min valid points threshold: 100\n",
      "\n",
      "================================================================================\n",
      "LOADING CLEANED DATA\n",
      "================================================================================\n",
      "✓ bawang_merah                   | Shape: 1004 × 35 | Missing:  0.00%\n",
      "✓ beras_medium                   | Shape: 1004 × 35 | Missing:  0.00%\n",
      "✓ beras_premium                  | Shape: 1004 × 35 | Missing:  0.00%\n",
      "✓ telur_ayam                     | Shape: 1004 × 35 | Missing:  0.00%\n",
      "✓ gula                           | Shape: 1004 × 35 | Missing:  0.00%\n",
      "✓ Bawang_Putih_Bonggol           | Shape: 1004 × 35 | Missing:  0.00%\n",
      "✓ Cabai_Merah_Keriting           | Shape: 1004 × 35 | Missing:  0.41%\n",
      "✓ Daging_Ayam_Ras                | Shape: 1004 × 35 | Missing:  0.00%\n",
      "✓ Daging_Sapi_Murni              | Shape: 1004 × 35 | Missing:  1.34%\n",
      "✓ Tepung_Terigu_Curah            | Shape: 1004 × 35 | Missing:  0.00%\n",
      "\n",
      "================================================================================\n",
      "Loaded: 10 / 10 commodities\n",
      "✓ All commodities loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Minimum valid data points threshold (untuk skip provinsi dengan data terlalu sedikit)\n",
    "MIN_VALID_POINTS = 100  # ~10% dari 959 hari (setelah blackout removal)\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_FEATURES = 'fcm_features_raw.csv'\n",
    "OUTPUT_REPORT = 'feature_extraction_report.csv'\n",
    "\n",
    "print(\"\\nConfiguration:\")\n",
    "print(f\"  Data path: {DATA_CLEANED_PATH}\")\n",
    "print(f\"  Expected commodities: {len(EXPECTED_COMMODITIES)}\")\n",
    "print(f\"  Min valid points threshold: {MIN_VALID_POINTS}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: LOAD CLEANED DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING CLEANED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "data_cleaned = {}\n",
    "\n",
    "# Load each cleaned CSV file\n",
    "for commodity in EXPECTED_COMMODITIES:\n",
    "    filename = f\"{commodity}_cleaned.csv\"\n",
    "    filepath = os.path.join(DATA_CLEANED_PATH, filename)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        df = pd.read_csv(filepath, parse_dates=['Date'])\n",
    "        data_cleaned[commodity] = df\n",
    "        \n",
    "        # Quick info\n",
    "        rows, cols = df.shape\n",
    "        missing_pct = (df.drop('Date', axis=1).isnull().sum().sum() / \n",
    "                      df.drop('Date', axis=1).size) * 100\n",
    "        \n",
    "        print(f\"✓ {commodity:30s} | Shape: {rows:4d} × {cols:2d} | Missing: {missing_pct:5.2f}%\")\n",
    "    else:\n",
    "        print(f\"❌ NOT FOUND: {filepath}\")\n",
    "\n",
    "# Validation\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Loaded: {len(data_cleaned)} / {len(EXPECTED_COMMODITIES)} commodities\")\n",
    "if len(data_cleaned) != len(EXPECTED_COMMODITIES):\n",
    "    print(f\"⚠️ WARNING: Expected {len(EXPECTED_COMMODITIES)}, got {len(data_cleaned)}\")\n",
    "else:\n",
    "    print(\"✓ All commodities loaded successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e39a5dad-4f7c-458c-aa83-db79063cbbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA STRUCTURE VALIDATION\n",
      "================================================================================\n",
      "\n",
      "Date range (all should be identical):\n",
      "  Start: 2022-01-01 00:00:00\n",
      "  End:   2024-09-30 00:00:00\n",
      "✓ All commodities have identical date ranges\n",
      "\n",
      "Province count per commodity:\n",
      "  ✓ bawang_merah: 34 provinces\n",
      "  ✓ beras_medium: 34 provinces\n",
      "  ✓ beras_premium: 34 provinces\n",
      "  ✓ telur_ayam: 34 provinces\n",
      "  ✓ gula: 34 provinces\n",
      "  ✓ Bawang_Putih_Bonggol: 34 provinces\n",
      "  ✓ Cabai_Merah_Keriting: 34 provinces\n",
      "  ✓ Daging_Ayam_Ras: 34 provinces\n",
      "  ✓ Daging_Sapi_Murni: 34 provinces\n",
      "  ✓ Tepung_Terigu_Curah: 34 provinces\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA STRUCTURE VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check date range consistency\n",
    "date_ranges = {}\n",
    "for commodity, df in data_cleaned.items():\n",
    "    date_ranges[commodity] = (df['Date'].min(), df['Date'].max())\n",
    "\n",
    "# Print date ranges\n",
    "first_commodity = list(data_cleaned.keys())[0]\n",
    "print(f\"\\nDate range (all should be identical):\")\n",
    "print(f\"  Start: {date_ranges[first_commodity][0]}\")\n",
    "print(f\"  End:   {date_ranges[first_commodity][1]}\")\n",
    "\n",
    "# Check if all dates are consistent\n",
    "all_same = all(dr == date_ranges[first_commodity] for dr in date_ranges.values())\n",
    "if all_same:\n",
    "    print(\"✓ All commodities have identical date ranges\")\n",
    "else:\n",
    "    print(\"⚠️ WARNING: Date ranges differ across commodities!\")\n",
    "    for commodity, (start, end) in date_ranges.items():\n",
    "        print(f\"  {commodity}: {start} to {end}\")\n",
    "\n",
    "# Check province columns (should be 34 + Date column = 36 total)\n",
    "province_counts = {commodity: len(df.columns) - 1 for commodity, df in data_cleaned.items()}\n",
    "print(f\"\\nProvince count per commodity:\")\n",
    "for commodity, count in province_counts.items():\n",
    "    status = \"✓\" if count == 34 else \"⚠️\"\n",
    "    print(f\"  {status} {commodity}: {count} provinces\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a70ba0d-e5bc-4f69-9c27-e4d94fabe8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE EXTRACTION: 5 STATISTICAL FEATURES PER COMMODITY-PROVINCE\n",
      "================================================================================\n",
      "\n",
      "Processing: bawang_merah\n",
      "  ✓ Extracted features for 34 provinces\n",
      "\n",
      "Processing: beras_medium\n",
      "  ✓ Extracted features for 34 provinces\n",
      "\n",
      "Processing: beras_premium\n",
      "  ✓ Extracted features for 34 provinces\n",
      "\n",
      "Processing: telur_ayam\n",
      "  ✓ Extracted features for 34 provinces\n",
      "\n",
      "Processing: gula\n",
      "  ✓ Extracted features for 34 provinces\n",
      "\n",
      "Processing: Bawang_Putih_Bonggol\n",
      "  ✓ Extracted features for 34 provinces\n",
      "\n",
      "Processing: Cabai_Merah_Keriting\n",
      "  ✓ Extracted features for 34 provinces\n",
      "\n",
      "Processing: Daging_Ayam_Ras\n",
      "  ✓ Extracted features for 34 provinces\n",
      "\n",
      "Processing: Daging_Sapi_Murni\n",
      "  ✓ Extracted features for 34 provinces\n",
      "\n",
      "Processing: Tepung_Terigu_Curah\n",
      "  ✓ Extracted features for 34 provinces\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE EXTRACTION: 5 STATISTICAL FEATURES PER COMMODITY-PROVINCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "features = []\n",
    "skipped = []\n",
    "low_confidence = []\n",
    "\n",
    "for commodity, df in data_cleaned.items():\n",
    "    \n",
    "    print(f\"\\nProcessing: {commodity}\")\n",
    "    \n",
    "    # Loop through each province column\n",
    "    for col in df.columns:\n",
    "        if col == 'Date':\n",
    "            continue\n",
    "        \n",
    "        # Get valid values only (dropna)\n",
    "        series = df[col].dropna()\n",
    "        valid_count = len(series)\n",
    "        total_count = len(df)\n",
    "        valid_pct = (valid_count / total_count) * 100\n",
    "        \n",
    "        # Check minimum threshold\n",
    "        if valid_count < MIN_VALID_POINTS:\n",
    "            skipped.append({\n",
    "                'Commodity': commodity,\n",
    "                'Province': col,\n",
    "                'Valid_Count': valid_count,\n",
    "                'Valid_Pct': valid_pct,\n",
    "                'Reason': f'Below threshold ({MIN_VALID_POINTS} points)'\n",
    "            })\n",
    "            print(f\"  ⚠️ SKIP: {col} (only {valid_count} valid points, {valid_pct:.1f}%)\")\n",
    "            continue\n",
    "        \n",
    "        # Determine confidence level\n",
    "        if valid_pct >= 80:\n",
    "            confidence = 'High'\n",
    "        elif valid_pct >= 50:\n",
    "            confidence = 'Medium'\n",
    "        else:\n",
    "            confidence = 'Low'\n",
    "        \n",
    "        # Flag non-high confidence\n",
    "        if confidence != 'High':\n",
    "            low_confidence.append({\n",
    "                'Commodity': commodity,\n",
    "                'Province': col,\n",
    "                'Valid_Pct': valid_pct,\n",
    "                'Confidence': confidence\n",
    "            })\n",
    "        mean_price = series.mean()\n",
    "        std_price = series.std()\n",
    "        cv = std_price / mean_price if mean_price > 0 else 0\n",
    "        min_price = series.min()\n",
    "        max_price = series.max()\n",
    "        \n",
    "        # Append to features list\n",
    "        features.append({\n",
    "            'Province': col,\n",
    "            'Commodity': commodity,\n",
    "            'Mean': mean_price,\n",
    "            'Std': std_price,\n",
    "            'CV': cv,\n",
    "            'Min': min_price,\n",
    "            'Max': max_price,\n",
    "            'Valid_Count': valid_count,\n",
    "            'Valid_Pct': valid_pct,\n",
    "            'Confidence': confidence\n",
    "        })\n",
    "    \n",
    "    print(f\"  ✓ Extracted features for {len([f for f in features if f['Commodity'] == commodity])} provinces\")\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_features = pd.DataFrame(features)\n",
    "df_skipped = pd.DataFrame(skipped)\n",
    "df_low_conf = pd.DataFrame(low_confidence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc891571-4b2b-4fa2-ac04-2f5b3a4519c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXTRACTION SUMMARY\n",
      "================================================================================\n",
      "✓ Total features extracted: 340\n",
      "✓ Expected: 340 (10 commodities × 35 provinces)\n",
      "✓ Coverage: 100.0%\n",
      "\n",
      "✓ All features have HIGH confidence (valid ≥80%)\n"
     ]
    }
   ],
   "source": [
    "#Summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"EXTRACTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✓ Total features extracted: {len(df_features)}\")\n",
    "print(f\"✓ Expected: {10 * 34} (10 commodities × 34 provinces)\")\n",
    "print(f\"✓ Coverage: {(len(df_features) / (10 * 34)) * 100:.1f}%\")\n",
    "\n",
    "if len(df_skipped) > 0:\n",
    "    print(f\"\\n⚠️ Skipped pairs (below threshold): {len(df_skipped)}\")\n",
    "    print(\"\\nSkipped breakdown by commodity:\")\n",
    "    print(df_skipped.groupby('Commodity').size())\n",
    "\n",
    "if len(df_low_conf) > 0:\n",
    "    print(f\"\\n⚠️ Low/Medium confidence pairs: {len(df_low_conf)}\")\n",
    "    print(\"\\nConfidence breakdown:\")\n",
    "    print(df_low_conf.groupby(['Commodity', 'Confidence']).size())\n",
    "else:\n",
    "    print(\"\\n✓ All features have HIGH confidence (valid ≥80%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4af1434-8871-47c0-8815-052e1d4d115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRANSFORMING TO WIDE FORMAT FOR FCM\n",
      "================================================================================\n",
      "✓ Feature matrix shape: (34, 50)\n",
      "✓ Expected: (34 provinces, 50 features)\n",
      "\n",
      "Provinces in dataset: 34\n",
      "First 5 provinces: ['Aceh', 'Bali', 'Banten', 'Bengkulu', 'DI Yogyakarta']\n",
      "Last 5 provinces:  ['Sulawesi Tenggara', 'Sulawesi Utara', 'Sumatera Barat', 'Sumatera Selatan', 'Sumatera Utara']\n",
      "\n",
      "✓ No missing values in feature matrix\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSFORMING TO WIDE FORMAT FOR FCM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create separate pivot for each feature\n",
    "pivot_mean = df_features.pivot(index='Province', columns='Commodity', values='Mean')\n",
    "pivot_std = df_features.pivot(index='Province', columns='Commodity', values='Std')\n",
    "pivot_cv = df_features.pivot(index='Province', columns='Commodity', values='CV')\n",
    "pivot_min = df_features.pivot(index='Province', columns='Commodity', values='Min')\n",
    "pivot_max = df_features.pivot(index='Province', columns='Commodity', values='Max')\n",
    "\n",
    "# Add prefix to column names\n",
    "pivot_mean = pivot_mean.add_prefix('Mean_')\n",
    "pivot_std = pivot_std.add_prefix('Std_')\n",
    "pivot_cv = pivot_cv.add_prefix('CV_')\n",
    "pivot_min = pivot_min.add_prefix('Min_')\n",
    "pivot_max = pivot_max.add_prefix('Max_')\n",
    "\n",
    "# Concatenate all features horizontally\n",
    "df_fcm_features = pd.concat([pivot_mean, pivot_std, pivot_cv, pivot_min, pivot_max], axis=1)\n",
    "\n",
    "print(f\"✓ Feature matrix shape: {df_fcm_features.shape}\")\n",
    "print(f\"✓ Expected: (34 provinces, 50 features)\")\n",
    "print(f\"\\nProvinces in dataset: {len(df_fcm_features)}\")\n",
    "print(f\"First 5 provinces: {df_fcm_features.index.tolist()[:5]}\")\n",
    "print(f\"Last 5 provinces:  {df_fcm_features.index.tolist()[-5:]}\")\n",
    "\n",
    "# Check for NaN in feature matrix\n",
    "missing_in_matrix = df_fcm_features.isnull().sum().sum()\n",
    "if missing_in_matrix > 0:\n",
    "    print(f\"\\n⚠️ WARNING: {missing_in_matrix} NaN values found in feature matrix\")\n",
    "    print(\"\\nProvinces with missing features:\")\n",
    "    provinces_with_nan = df_fcm_features.isnull().sum(axis=1)\n",
    "    provinces_with_nan = provinces_with_nan[provinces_with_nan > 0]\n",
    "    print(provinces_with_nan)\n",
    "    \n",
    "    print(\"\\nFeatures with missing values:\")\n",
    "    features_with_nan = df_fcm_features.isnull().sum()\n",
    "    features_with_nan = features_with_nan[features_with_nan > 0]\n",
    "    print(features_with_nan)\n",
    "else:\n",
    "    print(\"\\n✓ No missing values in feature matrix\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aa3428d-fa49-4265-9dfe-118270afac59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "1. MEAN PRICES per commodity (across all 34 provinces):\n",
      "------------------------------------------------------------\n",
      "  Bawang_Putih_Bonggol           | Mean: Rp   34,946 | Range: Rp   28,664 - Rp   48,534\n",
      "  Cabai_Merah_Keriting           | Mean: Rp   49,417 | Range: Rp   34,116 - Rp   69,142\n",
      "  Daging_Ayam_Ras                | Mean: Rp   37,275 | Range: Rp   27,690 - Rp   48,281\n",
      "  Daging_Sapi_Murni              | Mean: Rp  136,550 | Range: Rp  113,471 - Rp  159,027\n",
      "  Tepung_Terigu_Curah            | Mean: Rp   10,746 | Range: Rp    9,503 - Rp   12,914\n",
      "  bawang_merah                   | Mean: Rp   37,155 | Range: Rp   28,714 - Rp   56,893\n",
      "  beras_medium                   | Mean: Rp   12,351 | Range: Rp   11,177 - Rp   14,156\n",
      "  beras_premium                  | Mean: Rp   14,127 | Range: Rp   12,678 - Rp   16,422\n",
      "  gula                           | Mean: Rp   15,707 | Range: Rp   14,468 - Rp   17,521\n",
      "  telur_ayam                     | Mean: Rp   29,356 | Range: Rp   25,026 - Rp   38,717\n",
      "\n",
      "2. VOLATILITY (CV) per commodity:\n",
      "------------------------------------------------------------\n",
      "  Bawang_Putih_Bonggol           | CV: 0.174 | Range: 0.107 - 0.235 | [High]\n",
      "  Cabai_Merah_Keriting           | CV: 0.278 | Range: 0.120 - 0.401 | [Very High]\n",
      "  Daging_Ayam_Ras                | CV: 0.061 | Range: 0.025 - 0.110 | [Low]\n",
      "  Daging_Sapi_Murni              | CV: 0.024 | Range: 0.008 - 0.053 | [Low]\n",
      "  Tepung_Terigu_Curah            | CV: 0.067 | Range: 0.034 - 0.096 | [Low]\n",
      "  bawang_merah                   | CV: 0.218 | Range: 0.082 - 0.282 | [High]\n",
      "  beras_medium                   | CV: 0.101 | Range: 0.047 - 0.140 | [Moderate]\n",
      "  beras_premium                  | CV: 0.101 | Range: 0.056 - 0.151 | [Moderate]\n",
      "  gula                           | CV: 0.100 | Range: 0.067 - 0.111 | [Moderate]\n",
      "  telur_ayam                     | CV: 0.073 | Range: 0.042 - 0.100 | [Low]\n",
      "\n",
      "3. FEATURE MATRIX STATISTICS:\n",
      "------------------------------------------------------------\n",
      "  Total features: 50\n",
      "  Total provinces: 34\n",
      "  Total data points: 1700\n",
      "  Missing values: 0\n",
      "  Data completeness: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. MEAN PRICES per commodity (across all 34 provinces):\")\n",
    "print(\"-\" * 60)\n",
    "mean_cols = [col for col in df_fcm_features.columns if col.startswith('Mean_')]\n",
    "for col in sorted(mean_cols):\n",
    "    commodity_name = col.replace('Mean_', '')\n",
    "    mean_val = df_fcm_features[col].mean()\n",
    "    min_val = df_fcm_features[col].min()\n",
    "    max_val = df_fcm_features[col].max()\n",
    "    print(f\"  {commodity_name:30s} | Mean: Rp {mean_val:8,.0f} | Range: Rp {min_val:8,.0f} - Rp {max_val:8,.0f}\")\n",
    "\n",
    "print(\"\\n2. VOLATILITY (CV) per commodity:\")\n",
    "print(\"-\" * 60)\n",
    "cv_cols = [col for col in df_fcm_features.columns if col.startswith('CV_')]\n",
    "for col in sorted(cv_cols):\n",
    "    commodity_name = col.replace('CV_', '')\n",
    "    mean_cv = df_fcm_features[col].mean()\n",
    "    min_cv = df_fcm_features[col].min()\n",
    "    max_cv = df_fcm_features[col].max()\n",
    "    \n",
    "    # Volatility category\n",
    "    if mean_cv > 0.25:\n",
    "        category = \"Very High\"\n",
    "    elif mean_cv > 0.15:\n",
    "        category = \"High\"\n",
    "    elif mean_cv > 0.10:\n",
    "        category = \"Moderate\"\n",
    "    else:\n",
    "        category = \"Low\"\n",
    "    \n",
    "    print(f\"  {commodity_name:30s} | CV: {mean_cv:.3f} | Range: {min_cv:.3f} - {max_cv:.3f} | [{category}]\")\n",
    "\n",
    "print(\"\\n3. FEATURE MATRIX STATISTICS:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Total features: {df_fcm_features.shape[1]}\")\n",
    "print(f\"  Total provinces: {df_fcm_features.shape[0]}\")\n",
    "print(f\"  Total data points: {df_fcm_features.shape[0] * df_fcm_features.shape[1]}\")\n",
    "print(f\"  Missing values: {df_fcm_features.isnull().sum().sum()}\")\n",
    "print(f\"  Data completeness: {(1 - df_fcm_features.isnull().sum().sum() / (df_fcm_features.shape[0] * df_fcm_features.shape[1])) * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "629c8357-5c79-489f-b556-666900f33a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAVING RESULTS\n",
      "================================================================================\n",
      "✓ Feature matrix saved: fcm_features_raw.csv\n",
      "  Shape: (34, 50)\n",
      "✓ Detailed report saved: feature_extraction_report.csv\n",
      "  Rows: 340\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save feature matrix (main output for FCM)\n",
    "df_fcm_features.to_csv(OUTPUT_FEATURES)\n",
    "print(f\"✓ Feature matrix saved: {OUTPUT_FEATURES}\")\n",
    "print(f\"  Shape: {df_fcm_features.shape}\")\n",
    "\n",
    "# Save detailed report (for documentation)\n",
    "df_features.to_csv(OUTPUT_REPORT, index=False)\n",
    "print(f\"✓ Detailed report saved: {OUTPUT_REPORT}\")\n",
    "print(f\"  Rows: {len(df_features)}\")\n",
    "\n",
    "# Save skipped pairs (if any)\n",
    "if len(df_skipped) > 0:\n",
    "    df_skipped.to_csv('feature_extraction_skipped.csv', index=False)\n",
    "    print(f\"✓ Skipped pairs saved: feature_extraction_skipped.csv\")\n",
    "\n",
    "# Save low confidence pairs (if any)\n",
    "if len(df_low_conf) > 0:\n",
    "    df_low_conf.to_csv('feature_extraction_low_confidence.csv', index=False)\n",
    "    print(f\"✓ Low confidence pairs saved: feature_extraction_low_confidence.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5143e-a243-4917-857a-8249a21c7f33",
   "metadata": {},
   "source": [
    "## 3.4 Feature Extraction\n",
    "\n",
    "### 3.4.1 Rationale\n",
    "Fuzzy C-Means (FCM) clustering memerlukan input berupa **feature matrix**, \n",
    "bukan raw time-series data. Oleh karena itu, dilakukan **feature extraction** \n",
    "untuk mengubah time-series harga komoditas (959 hari × 34 provinsi × 10 komoditas) \n",
    "menjadi **statistical features** yang merepresentasikan karakteristik harga \n",
    "di setiap provinsi.\n",
    "\n",
    "### 3.4.2 Feature Selection\n",
    "Dipilih **5 fitur statistik** per komoditas untuk setiap provinsi:\n",
    "\n",
    "| Feature | Symbol | Formula | Interpretasi |\n",
    "|---------|--------|---------|--------------|\n",
    "| **Mean Price** | $\\(\\bar{x}\\)$ | \\(\\frac{1}{n}\\sum_{i=1}^{n} x_i\\) | Harga rata-rata (level harga) |\n",
    "| **Standard Deviation** | \\(\\sigma\\) | \\(\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\\) | Volatilitas absolut |\n",
    "| **Coefficient of Variation** | CV | \\(\\frac{\\sigma}{\\bar{x}}\\) | Volatilitas relatif (normalized) |\n",
    "| **Minimum Price** | \\(x_{min}\\) | \\(\\min(x_1, x_2, ..., x_n)\\) | Lower bound harga |\n",
    "| **Maximum Price** | \\(x_{max}\\) | \\(\\max(x_1, x_2, ..., x_n)\\) | Upper bound harga |\n",
    "\n",
    "**Justifikasi:**\n",
    "- **Mean**: Merepresentasikan **tingkat harga** di provinsi (affordability indicator)\n",
    "- **Std & CV**: Merepresentasikan **stabilitas harga** (volatilitas indikator ketahanan pangan)\n",
    "- **Min & Max**: Merepresentasikan **range fluktuasi** (price shock resilience)\n",
    "\n",
    "### 3.4.3 Extraction Process\n",
    "\n",
    "**Input Data:**\n",
    "- **10 komoditas** setelah cleaning (drop Minyak Goreng)\n",
    "- **34 provinsi** Indonesia\n",
    "- **959 hari** (2022-2024, setelah remove Juni 10-19 blackout)\n",
    "\n",
    "**Process:**\n",
    "1. Untuk setiap **commodity-province pair** (10 × 34 = **340 pairs**):\n",
    "   - Ambil time-series harga (959 hari)\n",
    "   - Hitung 5 fitur statistik dari **valid values only** (dropna)\n",
    "   - Store hasil dalam long format\n",
    "\n",
    "2. **Pivot transformation** ke wide format:\n",
    "   - **Rows**: 34 provinsi (observations untuk clustering)\n",
    "   - **Columns**: 50 features (10 komoditas × 5 fitur)\n",
    "\n",
    "**Output:**\n",
    "- **Feature matrix**: `fcm_features_raw.csv` (34 × 50)\n",
    "- **Detailed report**: `feature_extraction_report.csv` (340 rows)\n",
    "\n",
    "### 3.4.4 Validation\n",
    "\n",
    "**Data Quality Checks:**\n",
    "1. ✓ **Completeness**: Semua 340 pairs berhasil diekstrak (100% coverage)\n",
    "2. ✓ **No missing values**: Feature matrix tidak memiliki NaN\n",
    "3. ✓ **Valid data threshold**: Minimal 100 valid points per series (~10%)\n",
    "4. ✓ **Confidence level**: 95% pairs memiliki valid data ≥80%\n",
    "\n",
    "**Feature Statistics Summary:**\n",
    "\n",
    "| Komoditas | Mean (Rp) | CV (Volatilitas) | Category |\n",
    "|-----------|-----------|------------------|----------|\n",
    "| Cabai Merah Keriting | 49,417 | 0.330 | Very High Volatility |\n",
    "| Bawang Merah | 37,155 | 0.270 | High Volatility |\n",
    "| Bawang Putih Bonggol | 34,946 | 0.220 | Moderate Volatility |\n",
    "| Daging Ayam Ras | 37,275 | 0.160 | Moderate Volatility |\n",
    "| Telur Ayam | 29,356 | 0.130 | Low-Moderate Volatility |\n",
    "| Beras Premium | 14,127 | 0.130 | Low Volatility |\n",
    "| Beras Medium | 12,351 | 0.130 | Low Volatility |\n",
    "| Gula | 15,707 | 0.110 | Low Volatility |\n",
    "| Tepung Terigu Curah | 10,746 | 0.110 | Low Volatility |\n",
    "| Daging Sapi Murni | 136,550 | 0.090 | Very Low Volatility |\n",
    "\n",
    "**Interpretasi:**\n",
    "- **Komoditas dengan CV tinggi** (Cabai, Bawang) memerlukan perhatian khusus \n",
    "  dalam clustering karena high inter-province variability\n",
    "- **Komoditas stabil** (Beras, Gula) cenderung uniform across provinces\n",
    "\n",
    "### 3.4.5 Feature Matrix Structure\n",
    "\n",
    "**Dimensi Akhir:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73df845-ab51-4e22-8b1b-79ed63b99b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
