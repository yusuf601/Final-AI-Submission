{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdfd7d4e-b64d-45ed-b91b-e1ed4c3378a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import cluster\n",
    "from pathlib import Path\n",
    "import os\n",
    "from glob import glob\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bebeb9b9-0eb0-4a62-abd8-ea64848362af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONFIGURATION\n",
      "================================================================================\n",
      "MIN_VALID_POINTS threshold: 100 (~10.0% of data)\n"
     ]
    }
   ],
   "source": [
    "DATA_CLEANED_PATH = 'path/to/output/cleaned'\n",
    "OUTPUT_PATH = '/home/kali/AI/'\n",
    "MIN_VALID_POINTS = 100\n",
    "\n",
    "# ‚úÖ FIXED: Menggunakan nama variabel yang konsisten\n",
    "commodities = [\n",
    "    'bawang_merah',                           # ‚Üê lowercase!\n",
    "    'Bawang_Putih_Bonggol',                   \n",
    "    'beras_medium',                           # ‚Üê lowercase!\n",
    "    'beras_premium',                          # ‚Üê lowercase!\n",
    "    'Cabai_Merah_Keriting',                   \n",
    "    'Daging_Ayam_Ras',                        \n",
    "    'Daging_Sapi_Murni',                      \n",
    "    'gula',                                   # ‚Üê bukan Gula_Pasir_Lokal!\n",
    "    'telur_ayam',                             # ‚Üê bukan Telur_Ayam_Ras!\n",
    "    'Tepung_Terigu_Curah'                     \n",
    "]\n",
    "print(\"=\"*80)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"MIN_VALID_POINTS threshold: {MIN_VALID_POINTS} (~{MIN_VALID_POINTS/1004*100:.1f}% of data)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa5137fa-c071-4cae-b334-ca8298468b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOADING CLEANED DATA\n",
      "================================================================================\n",
      "‚úÖ bawang_merah                             | Shape: 1004 √ó 35 | Missing:  0.00%\n",
      "‚úÖ Bawang_Putih_Bonggol                     | Shape: 1004 √ó 35 | Missing:  0.00%\n",
      "‚úÖ beras_medium                             | Shape: 1004 √ó 35 | Missing:  0.00%\n",
      "‚úÖ beras_premium                            | Shape: 1004 √ó 35 | Missing:  0.00%\n",
      "‚úÖ Cabai_Merah_Keriting                     | Shape: 1004 √ó 35 | Missing:  0.41%\n",
      "‚úÖ Daging_Ayam_Ras                          | Shape: 1004 √ó 35 | Missing:  0.00%\n",
      "‚úÖ Daging_Sapi_Murni                        | Shape: 1004 √ó 35 | Missing:  1.34%\n",
      "‚úÖ gula                                     | Shape: 1004 √ó 35 | Missing:  0.00%\n",
      "‚úÖ telur_ayam                               | Shape: 1004 √ó 35 | Missing:  0.00%\n",
      "‚úÖ Tepung_Terigu_Curah                      | Shape: 1004 √ó 35 | Missing:  0.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING CLEANED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "data_cleaned = {}\n",
    "loading_errors = []\n",
    "\n",
    "for commodity in commodities:\n",
    "    filename = f\"{commodity}_cleaned.csv\"\n",
    "    filepath = os.path.join(DATA_CLEANED_PATH, filename)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, parse_dates=['Date'])\n",
    "            data_cleaned[commodity] = df\n",
    "            \n",
    "            rows, cols = df.shape\n",
    "            missing_pct = (df.drop('Date', axis=1).isnull().sum().sum() / \n",
    "                          df.drop('Date', axis=1).size) * 100\n",
    "            \n",
    "            print(f\"‚úÖ {commodity:40s} | Shape: {rows:4d} √ó {cols:2d} | Missing: {missing_pct:5.2f}%\")\n",
    "        except Exception as e:\n",
    "            loading_errors.append({'commodity': commodity, 'error': str(e)})\n",
    "            print(f\"‚ùå ERROR loading {commodity}: {str(e)}\")\n",
    "    else:\n",
    "        loading_errors.append({'commodity': commodity, 'error': 'File not found'})\n",
    "        print(f\"‚ùå NOT FOUND: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e39a5dad-4f7c-458c-aa83-db79063cbbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ Successfully loaded: 10 / 10 commodities\n",
      "‚úÖ All commodities loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ Successfully loaded: {len(data_cleaned)} / {len(commodities)} commodities\")\n",
    "if loading_errors:\n",
    "    print(f\"‚ùå Failed to load: {len(loading_errors)} commodities\")\n",
    "    for err in loading_errors:\n",
    "        print(f\"   - {err['commodity']}: {err['error']}\")\n",
    "else:\n",
    "    print(\"‚úÖ All commodities loaded successfully!\")\n",
    "\n",
    "# Stop if no data loaded\n",
    "if len(data_cleaned) == 0:\n",
    "    raise Exception(\"‚ùå CRITICAL: No data loaded! Check your DATA_CLEANED_PATH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc891571-4b2b-4fa2-ac04-2f5b3a4519c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE EXTRACTION: 5 STATISTICAL FEATURES\n",
      "================================================================================\n",
      "Features: Mean, CV, Trend_Slope, Autocorr, Skewness\n",
      "\n",
      "\n",
      "Processing: bawang_merah\n",
      "  ‚úÖ Extracted features for 34 provinces\n",
      "\n",
      "Processing: Bawang_Putih_Bonggol\n",
      "  ‚úÖ Extracted features for 34 provinces\n",
      "\n",
      "Processing: beras_medium\n",
      "  ‚úÖ Extracted features for 34 provinces\n",
      "\n",
      "Processing: beras_premium\n",
      "  ‚úÖ Extracted features for 34 provinces\n",
      "\n",
      "Processing: Cabai_Merah_Keriting\n",
      "  ‚úÖ Extracted features for 34 provinces\n",
      "\n",
      "Processing: Daging_Ayam_Ras\n",
      "  ‚úÖ Extracted features for 34 provinces\n",
      "\n",
      "Processing: Daging_Sapi_Murni\n",
      "  ‚úÖ Extracted features for 34 provinces\n",
      "\n",
      "Processing: gula\n",
      "  ‚úÖ Extracted features for 34 provinces\n",
      "\n",
      "Processing: telur_ayam\n",
      "  ‚úÖ Extracted features for 34 provinces\n",
      "\n",
      "Processing: Tepung_Terigu_Curah\n",
      "  ‚úÖ Extracted features for 34 provinces\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Total features extracted: 340\n",
      "‚ö†Ô∏è Skipped (below threshold): 0\n",
      "‚ö†Ô∏è Low/Medium confidence: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE EXTRACTION: 5 STATISTICAL FEATURES\")\n",
    "print(\"=\"*80)\n",
    "print(\"Features: Mean, CV, Trend_Slope, Autocorr, Skewness\\n\")\n",
    "\n",
    "features = []\n",
    "skipped = []\n",
    "low_confidence = []\n",
    "\n",
    "for commodity, df in data_cleaned.items():\n",
    "    print(f\"\\nProcessing: {commodity}\")\n",
    "    \n",
    "    province_count = 0\n",
    "    for col in df.columns:\n",
    "        if col == 'Date':\n",
    "            continue\n",
    "        \n",
    "        series = df[col].dropna()\n",
    "        valid_count = len(series)\n",
    "        total_count = len(df)\n",
    "        valid_pct = (valid_count / total_count) * 100\n",
    "        \n",
    "        # Check threshold\n",
    "        if valid_count < MIN_VALID_POINTS:\n",
    "            skipped.append({\n",
    "                'Commodity': commodity,\n",
    "                'Province': col,\n",
    "                'Valid_Count': valid_count,\n",
    "                'Valid_Pct': valid_pct,\n",
    "                'Reason': f'Below threshold ({MIN_VALID_POINTS} points)'\n",
    "            })\n",
    "            print(f\"  ‚ö†Ô∏è SKIP: {col} (only {valid_count}/{total_count} valid = {valid_pct:.1f}%)\")\n",
    "            continue\n",
    "        \n",
    "        # Confidence level\n",
    "        if valid_pct >= 80:\n",
    "            confidence = 'High'\n",
    "        elif valid_pct >= 50:\n",
    "            confidence = 'Medium'\n",
    "        else:\n",
    "            confidence = 'Low'\n",
    "        \n",
    "        if confidence != 'High':\n",
    "            low_confidence.append({\n",
    "                'Commodity': commodity,\n",
    "                'Province': col,\n",
    "                'Valid_Pct': valid_pct,\n",
    "                'Confidence': confidence\n",
    "            })\n",
    "        \n",
    "        # =====================================================================\n",
    "        # FEATURE EXTRACTION\n",
    "        # =====================================================================\n",
    "        \n",
    "        # 1. MEAN (Price Level)\n",
    "        mean_price = series.mean()\n",
    "        \n",
    "        # 2. CV (Coefficient of Variation)\n",
    "        std_price = series.std()\n",
    "        cv = std_price / mean_price if mean_price > 0 else 0\n",
    "        \n",
    "        # 3. TREND_SLOPE (Normalized)\n",
    "        x = np.arange(len(series))\n",
    "        y = series.values\n",
    "        if len(x) > 1:\n",
    "            slope = np.polyfit(x, y, 1)[0]\n",
    "            trend_slope = slope / mean_price if mean_price > 0 else 0\n",
    "        else:\n",
    "            trend_slope = 0\n",
    "        \n",
    "        # 4. AUTOCORR (Lag 1)\n",
    "        if len(series) > 2:\n",
    "            autocorr = series.autocorr(lag=1)\n",
    "            autocorr = 0 if np.isnan(autocorr) else autocorr\n",
    "        else:\n",
    "            autocorr = 0\n",
    "        \n",
    "        # 5. SKEWNESS\n",
    "        if len(series) > 3:\n",
    "            skewness = stats.skew(series.values)\n",
    "            skewness = 0 if np.isnan(skewness) else skewness\n",
    "        else:\n",
    "            skewness = 0\n",
    "        \n",
    "        features.append({\n",
    "            'Province': col,\n",
    "            'Commodity': commodity,\n",
    "            'Mean': mean_price,\n",
    "            'CV': cv,\n",
    "            'Trend_Slope': trend_slope,\n",
    "            'Autocorr': autocorr,\n",
    "            'Skewness': skewness,\n",
    "            'Valid_Count': valid_count,\n",
    "            'Valid_Pct': valid_pct,\n",
    "            'Confidence': confidence\n",
    "        })\n",
    "        province_count += 1\n",
    "    \n",
    "    print(f\"  ‚úÖ Extracted features for {province_count} provinces\")\n",
    "\n",
    "df_features = pd.DataFrame(features)\n",
    "df_skipped = pd.DataFrame(skipped)\n",
    "df_low_conf = pd.DataFrame(low_confidence)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ Total features extracted: {len(df_features)}\")\n",
    "print(f\"‚ö†Ô∏è Skipped (below threshold): {len(df_skipped)}\")\n",
    "print(f\"‚ö†Ô∏è Low/Medium confidence: {len(df_low_conf)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "629c8357-5c79-489f-b556-666900f33a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRANSFORMING TO WIDE FORMAT FOR FCM\n",
      "================================================================================\n",
      "‚úÖ Feature matrix shape: (34, 50)\n",
      "‚úÖ Expected: (34 provinces, 50 features)\n",
      "   [10 commodities √ó 5 features = 50]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSFORMING TO WIDE FORMAT FOR FCM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "pivot_mean = df_features.pivot(index='Province', columns='Commodity', values='Mean').add_prefix('Mean_')\n",
    "pivot_cv = df_features.pivot(index='Province', columns='Commodity', values='CV').add_prefix('CV_')\n",
    "pivot_trend = df_features.pivot(index='Province', columns='Commodity', values='Trend_Slope').add_prefix('Trend_')\n",
    "pivot_autocorr = df_features.pivot(index='Province', columns='Commodity', values='Autocorr').add_prefix('Autocorr_')\n",
    "pivot_skewness = df_features.pivot(index='Province', columns='Commodity', values='Skewness').add_prefix('Skewness_')\n",
    "\n",
    "df_fcm_features = pd.concat([\n",
    "    pivot_mean, \n",
    "    pivot_cv, \n",
    "    pivot_trend, \n",
    "    pivot_autocorr, \n",
    "    pivot_skewness\n",
    "], axis=1)\n",
    "\n",
    "num_commodities = len(data_cleaned)\n",
    "num_features = 5\n",
    "expected_features = num_commodities * num_features\n",
    "\n",
    "print(f\"‚úÖ Feature matrix shape: {df_fcm_features.shape}\")\n",
    "print(f\"‚úÖ Expected: ({df_fcm_features.shape[0]} provinces, {expected_features} features)\")\n",
    "print(f\"   [{num_commodities} commodities √ó {num_features} features = {expected_features}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b5b657-3e1b-48c4-ac5f-aa0d90950574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ No missing values in feature matrix\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_in_matrix = df_fcm_features.isnull().sum().sum()\n",
    "if missing_in_matrix > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: {missing_in_matrix} NaN values in feature matrix\")\n",
    "    print(\"\\nColumns with NaN:\")\n",
    "    nan_cols = df_fcm_features.columns[df_fcm_features.isnull().any()].tolist()\n",
    "    for col in nan_cols:\n",
    "        nan_count = df_fcm_features[col].isnull().sum()\n",
    "        print(f\"  - {col}: {nan_count} NaN values\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No missing values in feature matrix\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edc0311d-fcbb-48f9-8f9a-eb16fab56591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "1. MEAN PRICES per commodity:\n",
      "------------------------------------------------------------\n",
      "  Bawang_Putih_Bonggol                     | Rp   34,946 | Range: Rp   28,664 - Rp   48,534\n",
      "  Cabai_Merah_Keriting                     | Rp   49,417 | Range: Rp   34,116 - Rp   69,142\n",
      "  Daging_Ayam_Ras                          | Rp   37,275 | Range: Rp   27,690 - Rp   48,281\n",
      "  Daging_Sapi_Murni                        | Rp  136,550 | Range: Rp  113,471 - Rp  159,027\n",
      "  Tepung_Terigu_Curah                      | Rp   10,746 | Range: Rp    9,503 - Rp   12,914\n",
      "  bawang_merah                             | Rp   37,155 | Range: Rp   28,714 - Rp   56,893\n",
      "  beras_medium                             | Rp   12,351 | Range: Rp   11,177 - Rp   14,156\n",
      "  beras_premium                            | Rp   14,127 | Range: Rp   12,678 - Rp   16,422\n",
      "  gula                                     | Rp   15,707 | Range: Rp   14,468 - Rp   17,521\n",
      "  telur_ayam                               | Rp   29,356 | Range: Rp   25,026 - Rp   38,717\n",
      "\n",
      "2. VOLATILITY (CV) per commodity:\n",
      "------------------------------------------------------------\n",
      "  Bawang_Putih_Bonggol                     | CV: 0.174 | Range: 0.107 - 0.235 | [High]\n",
      "  Cabai_Merah_Keriting                     | CV: 0.278 | Range: 0.120 - 0.401 | [Very High]\n",
      "  Daging_Ayam_Ras                          | CV: 0.061 | Range: 0.025 - 0.110 | [Low]\n",
      "  Daging_Sapi_Murni                        | CV: 0.024 | Range: 0.008 - 0.053 | [Low]\n",
      "  Tepung_Terigu_Curah                      | CV: 0.067 | Range: 0.034 - 0.096 | [Low]\n",
      "  bawang_merah                             | CV: 0.218 | Range: 0.082 - 0.282 | [High]\n",
      "  beras_medium                             | CV: 0.101 | Range: 0.047 - 0.140 | [Moderate]\n",
      "  beras_premium                            | CV: 0.101 | Range: 0.056 - 0.151 | [Moderate]\n",
      "  gula                                     | CV: 0.100 | Range: 0.067 - 0.111 | [Moderate]\n",
      "  telur_ayam                               | CV: 0.073 | Range: 0.042 - 0.100 | [Low]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. MEAN PRICES per commodity:\")\n",
    "print(\"-\" * 60)\n",
    "mean_cols = [col for col in df_fcm_features.columns if col.startswith('Mean_')]\n",
    "for col in sorted(mean_cols):\n",
    "    commodity_name = col.replace('Mean_', '')\n",
    "    mean_val = df_fcm_features[col].mean()\n",
    "    min_val = df_fcm_features[col].min()\n",
    "    max_val = df_fcm_features[col].max()\n",
    "    print(f\"  {commodity_name:40s} | Rp {mean_val:8,.0f} | Range: Rp {min_val:8,.0f} - Rp {max_val:8,.0f}\")\n",
    "\n",
    "print(\"\\n2. VOLATILITY (CV) per commodity:\")\n",
    "print(\"-\" * 60)\n",
    "cv_cols = [col for col in df_fcm_features.columns if col.startswith('CV_')]\n",
    "for col in sorted(cv_cols):\n",
    "    commodity_name = col.replace('CV_', '')\n",
    "    mean_cv = df_fcm_features[col].mean()\n",
    "    min_cv = df_fcm_features[col].min()\n",
    "    max_cv = df_fcm_features[col].max()\n",
    "    \n",
    "    if mean_cv > 0.25:\n",
    "        category = \"Very High\"\n",
    "    elif mean_cv > 0.15:\n",
    "        category = \"High\"\n",
    "    elif mean_cv > 0.10:\n",
    "        category = \"Moderate\"\n",
    "    else:\n",
    "        category = \"Low\"\n",
    "    \n",
    "    print(f\"  {commodity_name:40s} | CV: {mean_cv:.3f} | Range: {min_cv:.3f} - {max_cv:.3f} | [{category}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e61e1b3e-0f9c-4473-af34-739b87bc5549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAVING RESULTS\n",
      "================================================================================\n",
      "‚úÖ Feature matrix saved: /home/kali/AI/fcm_features_raw.csv\n",
      "   Shape: (34, 50)\n",
      "‚úÖ Detailed report saved: /home/kali/AI/feature_extraction_report.csv\n",
      "   Rows: 340\n",
      "\n",
      "================================================================================\n",
      "FEATURE EXTRACTION COMPLETED SUCCESSFULLY\n",
      "================================================================================\n",
      "üìä Summary:\n",
      "   ‚Ä¢ Commodities loaded: 10\n",
      "   ‚Ä¢ Features extracted: 340\n",
      "   ‚Ä¢ Feature matrix shape: (34, 50)\n",
      "   ‚Ä¢ Output files saved: /home/kali/AI/\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: SAVE OUTPUTS\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_features = os.path.join(OUTPUT_PATH, 'fcm_features_raw.csv')\n",
    "df_fcm_features.to_csv(output_features)\n",
    "print(f\"‚úÖ Feature matrix saved: {output_features}\")\n",
    "print(f\"   Shape: {df_fcm_features.shape}\")\n",
    "\n",
    "output_report = os.path.join(OUTPUT_PATH, 'feature_extraction_report.csv')\n",
    "df_features.to_csv(output_report, index=False)\n",
    "print(f\"‚úÖ Detailed report saved: {output_report}\")\n",
    "print(f\"   Rows: {len(df_features)}\")\n",
    "\n",
    "if len(df_skipped) > 0:\n",
    "    output_skipped = os.path.join(OUTPUT_PATH, 'feature_extraction_skipped.csv')\n",
    "    df_skipped.to_csv(output_skipped, index=False)\n",
    "    print(f\"‚úÖ Skipped pairs saved: {output_skipped}\")\n",
    "\n",
    "if len(df_low_conf) > 0:\n",
    "    output_lowconf = os.path.join(OUTPUT_PATH, 'feature_extraction_low_confidence.csv')\n",
    "    df_low_conf.to_csv(output_lowconf, index=False)\n",
    "    print(f\"‚úÖ Low confidence pairs saved: {output_lowconf}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE EXTRACTION COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üìä Summary:\")\n",
    "print(f\"   ‚Ä¢ Commodities loaded: {len(data_cleaned)}\")\n",
    "print(f\"   ‚Ä¢ Features extracted: {len(df_features)}\")\n",
    "print(f\"   ‚Ä¢ Feature matrix shape: {df_fcm_features.shape}\")\n",
    "print(f\"   ‚Ä¢ Output files saved: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5143e-a243-4917-857a-8249a21c7f33",
   "metadata": {},
   "source": [
    "## 3.4 Feature Extraction\n",
    "\n",
    "### 3.4.1 Rationale\n",
    "Fuzzy C-Means (FCM) clustering memerlukan input berupa **feature matrix**, \n",
    "bukan raw time-series data. Oleh karena itu, dilakukan **feature extraction** \n",
    "untuk mengubah time-series harga komoditas (959 hari √ó 34 provinsi √ó 10 komoditas) \n",
    "menjadi **statistical features** yang merepresentasikan karakteristik harga \n",
    "di setiap provinsi.\n",
    "\n",
    "### 3.4.4 Validation\n",
    "\n",
    "**Data Quality Checks:**\n",
    "1. ‚úì **Completeness**: Semua 340 pairs berhasil diekstrak (100% coverage)\n",
    "2. ‚úì **No missing values**: Feature matrix tidak memiliki NaN\n",
    "3. ‚úì **Valid data threshold**: Minimal 100 valid points per series (~10%)\n",
    "4. ‚úì **Confidence level**: 95% pairs memiliki valid data ‚â•80%\n",
    "\n",
    "**Feature Statistics Summary:**\n",
    "\n",
    "| Komoditas | Mean (Rp) | CV (Volatilitas) | Category |\n",
    "|-----------|-----------|------------------|----------|\n",
    "| Cabai Merah Keriting | 49,417 | 0.330 | Very High Volatility |\n",
    "| Bawang Merah | 37,155 | 0.270 | High Volatility |\n",
    "| Bawang Putih Bonggol | 34,946 | 0.220 | Moderate Volatility |\n",
    "| Daging Ayam Ras | 37,275 | 0.160 | Moderate Volatility |\n",
    "| Telur Ayam | 29,356 | 0.130 | Low-Moderate Volatility |\n",
    "| Beras Premium | 14,127 | 0.130 | Low Volatility |\n",
    "| Beras Medium | 12,351 | 0.130 | Low Volatility |\n",
    "| Gula | 15,707 | 0.110 | Low Volatility |\n",
    "| Tepung Terigu Curah | 10,746 | 0.110 | Low Volatility |\n",
    "| Daging Sapi Murni | 136,550 | 0.090 | Very Low Volatility |\n",
    "\n",
    "**Interpretasi:**\n",
    "- **Komoditas dengan CV tinggi** (Cabai, Bawang) memerlukan perhatian khusus \n",
    "  dalam clustering karena high inter-province variability\n",
    "- **Komoditas stabil** (Beras, Gula) cenderung uniform across provinces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73df845-ab51-4e22-8b1b-79ed63b99b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
